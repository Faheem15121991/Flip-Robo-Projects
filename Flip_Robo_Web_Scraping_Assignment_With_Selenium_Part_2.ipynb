{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the browser to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering url\n",
    "url=\"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Data Analyst” in “Skill,Designations,Companies” field \n",
    "job_search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "job_search.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Bangalore” in “enter the location” field \n",
    "location_search=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "location_search.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for the first 10 jobs results.\n",
    "job_titles=[]\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")[:10]\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "company_names=[]\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")[:10]\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "        \n",
    "experience_list=[]\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")[:10]\n",
    "for i in exp_tags:\n",
    "    experience_list.append(i.text)\n",
    "        \n",
    "salary_list=[]\n",
    "sal_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']/span\")[:10]\n",
    "for i in sal_tags:\n",
    "    salary_list.append(i.text)\n",
    "        \n",
    "locations_list=[]\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")[:10]\n",
    "for i in loc_tags:\n",
    "    locations_list.append(i.text)\n",
    "        \n",
    "jobs=pd.DataFrame({})\n",
    "jobs['job_titles']=job_titles\n",
    "jobs['company_names']=company_names\n",
    "jobs['locations_list']=locations_list\n",
    "jobs['experience_list']=experience_list\n",
    "jobs['salary_list']=salary_list\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "      <th>salary_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst/ Data Analyst/ MIS Executive ...</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>Mumbai, Bengaluru, Hyderabad</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>Bengaluru, Kolkata</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>3,25,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - MySQL/PostgreSQL</td>\n",
       "      <td>Astegic</td>\n",
       "      <td>Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0  Business Analyst/ Data Analyst/ MIS Executive ...   \n",
       "1              Data Scientist/Data Analyst-immediate   \n",
       "2                                       Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                     Data Analyst - O2C - Bangalore   \n",
       "8     Business Data Analyst - Database Design/Mining   \n",
       "9                    Data Analyst - MySQL/PostgreSQL   \n",
       "\n",
       "                                       company_names  \\\n",
       "0                                 Schneider Electric   \n",
       "1  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "2                                  Applied Materials   \n",
       "3       Cognizant Technology Solutions India Pvt Ltd   \n",
       "4            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "5       Cognizant Technology Solutions India Pvt Ltd   \n",
       "6                Shell India Markets Private Limited   \n",
       "7                             RANDSTAD INDIA PVT LTD   \n",
       "8                                        AugmatrixGo   \n",
       "9                                            Astegic   \n",
       "\n",
       "                                      locations_list experience_list  \\\n",
       "0                              Bengaluru / Bangalore         2-5 Yrs   \n",
       "1                Chennai, Pune, Bengaluru, Hyderabad         0-3 Yrs   \n",
       "2                                          Bengaluru        6-11 Yrs   \n",
       "3                       Mumbai, Bengaluru, Hyderabad         2-3 Yrs   \n",
       "4                                          Bengaluru         2-7 Yrs   \n",
       "5                                 Bengaluru, Kolkata         3-4 Yrs   \n",
       "6                                          Bengaluru         5-8 Yrs   \n",
       "7                                          Bengaluru         2-4 Yrs   \n",
       "8                                          Bengaluru         2-5 Yrs   \n",
       "9  Pune, Mumbai, Bengaluru, Hyderabad, Noida, Jaipur        5-10 Yrs   \n",
       "\n",
       "               salary_list  \n",
       "0            Not disclosed  \n",
       "1  3,50,000 - 4,50,000 PA.  \n",
       "2            Not disclosed  \n",
       "3            Not disclosed  \n",
       "4            Not disclosed  \n",
       "5            Not disclosed  \n",
       "6            Not disclosed  \n",
       "7  3,25,000 - 4,50,000 PA.  \n",
       "8            Not disclosed  \n",
       "9            Not disclosed  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the browser to webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering url\n",
    "url=\"https://www.naukri.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist/Data Analyst-immediate',\n",
       " 'HCL hiring Data scientist with exp in machine learning &SQL-Bangalore!',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - Machine Learning']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAIA-Center For Artificial Intelligence & Advanced Analytics',\n",
       " 'HCL Technologies Limited',\n",
       " 'AugmatrixGo',\n",
       " 'BLUE YONDER INDIA PRIVATE LIMITED']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the company_name  \n",
    "companies=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Pune, Bengaluru, Hyderabad', 'Bengaluru', 'Bengaluru', 'Bengaluru']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the full job-description, for scraping full job description we have to go in each of the jobs separately...\n",
    "urls=[i.get_attribute(\"href\") for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Dear Candidate\\n\\nSchedule a Telephonic Interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring Data scientist with exp in machine ...</td>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Dear Candidate,\\n\\nGreetings from HCL!!!\\nWe a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\n\\n\\n- Selecting fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Associate - Data Scientist/ML Engineer</td>\n",
       "      <td>Pricewaterhouse Coopers Private Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Day-to-Day Responsibilities\\nDesign and develo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description\\nAt Philips, data is in the ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning - Remote Wor...</td>\n",
       "      <td>Doji Ltd</td>\n",
       "      <td>Delhi NCR, Bengaluru, Anywhere in India</td>\n",
       "      <td>Please note that this role will be Remote / Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Developer - Data Scientist / NLP / Ma...</td>\n",
       "      <td>Cunesoft India Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Roles and Responsibilities\\nWe are looking for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  HCL hiring Data scientist with exp in machine ...   \n",
       "2                  Data Scientist - Machine Learning   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4                  Data Scientist - Machine Learning   \n",
       "5      Senior Associate - Data Scientist/ML Engineer   \n",
       "6                              Senior Data Scientist   \n",
       "7  Data Scientist - Machine Learning - Remote Wor...   \n",
       "8  Software Developer - Data Scientist / NLP / Ma...   \n",
       "9                                 Sr. Data Scientist   \n",
       "\n",
       "                                        company_name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                           HCL Technologies Limited   \n",
       "2                                        AugmatrixGo   \n",
       "3                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "4                  BLUE YONDER INDIA PRIVATE LIMITED   \n",
       "5            Pricewaterhouse Coopers Private Limited   \n",
       "6                              Philips India Limited   \n",
       "7                                           Doji Ltd   \n",
       "8                     Cunesoft India Private Limited   \n",
       "9                                             NetApp   \n",
       "\n",
       "                              job_location  \\\n",
       "0      Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                Bengaluru   \n",
       "2                                Bengaluru   \n",
       "3                                Bengaluru   \n",
       "4                                Bengaluru   \n",
       "5                                Bengaluru   \n",
       "6                                Bengaluru   \n",
       "7  Delhi NCR, Bengaluru, Anywhere in India   \n",
       "8                    Bengaluru / Bangalore   \n",
       "9                                Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Dear Candidate\\n\\nSchedule a Telephonic Interv...  \n",
       "1  Dear Candidate,\\n\\nGreetings from HCL!!!\\nWe a...  \n",
       "2  Roles and Responsibilities\\n\\n\\n- Selecting fe...  \n",
       "3                                                ---  \n",
       "4                                                ---  \n",
       "5  Day-to-Day Responsibilities\\nDesign and develo...  \n",
       "6  Job Description\\nAt Philips, data is in the ce...  \n",
       "7  Please note that this role will be Remote / Ho...  \n",
       "8  Roles and Responsibilities\\nWe are looking for...  \n",
       "9                                                ---  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":job_description[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the browser to webdriver.\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Naukri.com website.\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search button.\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists for scraping data.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the location check box of 'Delhi/NCR'.\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi/NCR']\")\n",
    "\n",
    "# Clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the salary check box and clicking on salary of 3-6 Lakhs.\n",
    "loc=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "\n",
    "# Clicking the check box\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jubna',\n",
       " 'tech mahindra ltd',\n",
       " 'Air Asia India Limited',\n",
       " 'Amity University',\n",
       " 'Talent Acceleration Corridor',\n",
       " 'Aerial Telecom Solutions Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Delhivery',\n",
       " 'Eighteen Pixels India Private Limited',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'HyreFox Consultants Pvt Ltd',\n",
       " 'GABA Consultancy services',\n",
       " 'iNICU',\n",
       " 'Sentieo',\n",
       " 'Mahajan Imaging',\n",
       " 'Mahajan Imaging',\n",
       " 'TalPro',\n",
       " 'World Wide Technology',\n",
       " 'T & A Solutions',\n",
       " 'itForte Staffing Services Private Ltd.']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida', 'Noida', 'Delhi NCR, Gurgaon', 'Faridabad, Delhi NCR, Ghaziabad']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "job_location[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - Python/Machine Learning',\n",
       " 'Tech Mahindra hiring For Data Scientist- Noida',\n",
       " 'Data Scientist - Commercial Planning and Analysis',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "    \n",
    "job_title[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-8 Yrs', '5-10 Yrs', '1-6 Yrs', '6-8 Yrs']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "experience_required[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Mahindra hiring For Data Scientist- Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine Learning/ Artificial ...</td>\n",
       "      <td>Delhi/NCR Delhi NCR, Noida</td>\n",
       "      <td>Talent Acceleration Corridor</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Eighteen Pixels India Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0           Data Scientist - Python/Machine Learning   \n",
       "1     Tech Mahindra hiring For Data Scientist- Noida   \n",
       "2  Data Scientist - Commercial Planning and Analysis   \n",
       "3                                     Data Scientist   \n",
       "4  Data Scientist - Machine Learning/ Artificial ...   \n",
       "5  GCP Skilled Analytics Resources (Data engineer...   \n",
       "6                                     Data Scientist   \n",
       "7                    Data Scientist Machine Learning   \n",
       "8                                     Data Scientist   \n",
       "9                  Business Analyst - Data Scientist   \n",
       "\n",
       "                      job_location                           company_name  \\\n",
       "0                            Noida                                  Jubna   \n",
       "1                            Noida                      tech mahindra ltd   \n",
       "2               Delhi NCR, Gurgaon                 Air Asia India Limited   \n",
       "3  Faridabad, Delhi NCR, Ghaziabad                       Amity University   \n",
       "4       Delhi/NCR Delhi NCR, Noida           Talent Acceleration Corridor   \n",
       "5         Pune, Bengaluru, Gurgaon     Aerial Telecom Solutions Pvt. Ltd.   \n",
       "6                 Gurgaon Gurugram                 IBM India Pvt. Limited   \n",
       "7                          Gurgaon                              Delhivery   \n",
       "8                        Delhi NCR  Eighteen Pixels India Private Limited   \n",
       "9                          Gurgaon            HyreFox Consultants Pvt Ltd   \n",
       "\n",
       "  experience_required  \n",
       "0             5-8 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             1-6 Yrs  \n",
       "3             6-8 Yrs  \n",
       "4            6-11 Yrs  \n",
       "5             3-8 Yrs  \n",
       "6             3-5 Yrs  \n",
       "7             1-3 Yrs  \n",
       "8             2-6 Yrs  \n",
       "9             3-5 Yrs  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"job_location\":job_location[0:10],\"company_name\":company_name[0:10],\"experience_required\":experience_required[0:10]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glassdoor(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Sign in Option\n",
    "    sign_in=driver.find_element_by_xpath(\"//div[@class='locked-home-sign-in']/a\")\n",
    "    url=sign_in.get_attribute('href')\n",
    "    driver_2=webdriver.Chrome(options=chrome_options)\n",
    "    driver_2.get(url)\n",
    "    time.sleep(5)\n",
    "    email=driver_2.find_element_by_id('userEmail')\n",
    "    email.send_keys('demo15121991@gmail.com')\n",
    "    passw=driver_2.find_element_by_id('userPassword')\n",
    "    passw.send_keys('demo@567')\n",
    "    sign_in_button=driver_2.find_element_by_xpath(\"//div/button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "    sign_in_button.click()\n",
    "    time.sleep(5)\n",
    "    driver.close()\n",
    "    \n",
    "    # searching required fields\n",
    "    job_search=driver_2.find_element_by_id('sc.keyword')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver_2.find_element_by_id('sc.location')\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    location.send_keys(Keys.CONTROL + \"a\")\n",
    "    location.send_keys(Keys.DELETE)\n",
    "    location.send_keys('Noida')\n",
    "    \n",
    "    search_button=driver_2.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    company_name=[]\n",
    "    days_posted=[]\n",
    "    rating=[]\n",
    "    \n",
    "    # Company and days are available but for ratings need to open in new window as some are absent/missing\n",
    "    # Opening new window\n",
    "    from selenium.common.exceptions import NoSuchElementException         # Importing Exception\n",
    "    new_page=driver_2.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']/a\")[:10]\n",
    "    \n",
    "    for i in new_page:\n",
    "        url=i.get_attribute('href')\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        driver_3.get(url)\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            a=driver_3.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "            rating.append(a.text.replace('\\n★',''))\n",
    "        except NoSuchElementException as e:\n",
    "            rating.append(\"No Rating\")\n",
    "        driver_3.close() \n",
    "        \n",
    "    comps=driver_2.find_elements_by_xpath(\"//div[@class='jobHeader d-flex justify-content-between align-items-start']/a/span\")[:10]\n",
    "    for i in comps:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "    days=driver_2.find_elements_by_xpath(\"//div[@data-test='job-age']\")[:10]\n",
    "    for i in days:\n",
    "        days_posted.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['company_names']=company_name\n",
    "    jobs['days_posted']=days_posted\n",
    "    jobs['rating']=rating\n",
    "    \n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_names</th>\n",
       "      <th>days_posted</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Builder.ai - What would you Build?</td>\n",
       "      <td>24d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brickred</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terra Economics &amp; Analytics Lab (TEAL)</td>\n",
       "      <td>10d</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abc consultants</td>\n",
       "      <td>9d</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>8d</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Algoscale</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>17d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            company_names days_posted rating\n",
       "0                                 Genpact          9d    3.8\n",
       "1                      UnitedHealth Group          1d    3.5\n",
       "2      Builder.ai - What would you Build?         24d    3.6\n",
       "3                                Brickred         24h    3.7\n",
       "4  Terra Economics & Analytics Lab (TEAL)         10d    4.9\n",
       "5                         abc consultants          9d    4.2\n",
       "6                         Priority Vendor          8d    4.0\n",
       "7                               Algoscale          8d    3.7\n",
       "8                          Biz2Credit Inc         17d    3.7\n",
       "9                    Gauge Data Solutions          8d    3.1"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor('https://www.glassdoor.co.in/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glassdoor_2(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "     \n",
    "    # searching required fields\n",
    "    job_search=driver.find_element_by_id('KeywordSearch')\n",
    "    job_search.send_keys('Data Scientist')\n",
    "    \n",
    "    location=driver.find_element_by_id('LocationSearch')\n",
    "    location.clear()\n",
    "    location.send_keys('Noida')\n",
    "        \n",
    "    search_buton=driver.find_element_by_id(\"HeroSearchButton\")\n",
    "    search_buton.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    comp=[]\n",
    "    number_of_salaries=[]\n",
    "    avg_salary=[]\n",
    "    min_salary=[]\n",
    "    max_salary=[]\n",
    "    \n",
    "    a=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")[:10]\n",
    "    for i in a:\n",
    "        comp.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")[:10]\n",
    "    for i in a:\n",
    "        avg_salary.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[1]\")[:10]\n",
    "    for i in a:\n",
    "        min_salary.append(i.text)\n",
    "        \n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']/span[2]\")[:10]\n",
    "    for i in a:\n",
    "        max_salary.append(i.text)\n",
    "         \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['company_names']=comp\n",
    "    jobs['avg_salary']=avg_salary\n",
    "    jobs['min_salary']=min_salary\n",
    "    jobs['max_salary']=max_salary\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_names</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,81,419</td>\n",
       "      <td>₹456K</td>\n",
       "      <td>₹11,789K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 9,98,925</td>\n",
       "      <td>₹585K</td>\n",
       "      <td>₹2,200K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,90,026</td>\n",
       "      <td>₹420K</td>\n",
       "      <td>₹1,636K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,02,000</td>\n",
       "      <td>₹336K</td>\n",
       "      <td>₹1,024K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,71,657</td>\n",
       "      <td>₹595K</td>\n",
       "      <td>₹2,769K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 12,22,902</td>\n",
       "      <td>₹727K</td>\n",
       "      <td>₹1,597K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,91,015</td>\n",
       "      <td>₹509K</td>\n",
       "      <td>₹1,168K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹ 12,15,138</td>\n",
       "      <td>₹629K</td>\n",
       "      <td>₹1,719K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹ 10,21,889</td>\n",
       "      <td>₹804K</td>\n",
       "      <td>₹1,281K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 10,00,000</td>\n",
       "      <td>₹205K</td>\n",
       "      <td>₹1,835K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company_names   avg_salary min_salary max_salary\n",
       "0                       Delhivery  ₹ 12,81,419      ₹456K   ₹11,789K\n",
       "1                       Accenture   ₹ 9,98,925      ₹585K    ₹2,200K\n",
       "2              Ericsson-Worldwide   ₹ 7,90,026      ₹420K    ₹1,636K\n",
       "3       Tata Consultancy Services   ₹ 6,02,000      ₹336K    ₹1,024K\n",
       "4                             IBM   ₹ 7,71,657      ₹595K    ₹2,769K\n",
       "5              UnitedHealth Group  ₹ 12,22,902      ₹727K    ₹1,597K\n",
       "6              Valiance Solutions   ₹ 7,91,015      ₹509K    ₹1,168K\n",
       "7                      Innovaccer  ₹ 12,15,138      ₹629K    ₹1,719K\n",
       "8  Cognizant Technology Solutions  ₹ 10,21,889      ₹804K    ₹1,281K\n",
       "9                   ZS Associates  ₹ 10,00,000      ₹205K    ₹1,835K"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=glassdoor_2('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sunglasses')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    Product_description=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            Product_description.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['Product_description']=Product_description\n",
    "    jobs['price']=price\n",
    "    jobs['discount']=discount\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    driver_3.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹351</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "      <td>₹527</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riffko</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹170</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MGKNYAH</td>\n",
       "      <td>UV Protection Round, Aviator Sunglasses (Free ...</td>\n",
       "      <td>₹152</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection, Gradient Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹269</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Scaglia</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹160</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>shadz</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹104</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Azmani</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                                Product_description price  \\\n",
       "0          Royal Son                   Mirrored Aviator Sunglasses (55)  ₹351   \n",
       "1          ROYAL SON         UV Protection Retro Square Sunglasses (88)  ₹527   \n",
       "2             Riffko             UV Protection Wayfarer Sunglasses (55)  ₹170   \n",
       "3     FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...  ₹199   \n",
       "4   shah collections  UV Protection, Polarized, Mirrored Rectangular...  ₹219   \n",
       "..               ...                                                ...   ...   \n",
       "95           MGKNYAH  UV Protection Round, Aviator Sunglasses (Free ...  ₹152   \n",
       "96            Gansta   UV Protection, Gradient Wayfarer Sunglasses (53)  ₹269   \n",
       "97           Scaglia              UV Protection Aviator Sunglasses (58)  ₹160   \n",
       "98             shadz                UV Protection Round Sunglasses (50)  ₹104   \n",
       "99            Azmani             UV Protection Wayfarer Sunglasses (53)  ₹299   \n",
       "\n",
       "   discount  \n",
       "0   76% off  \n",
       "1   73% off  \n",
       "2   85% off  \n",
       "3   84% off  \n",
       "4   78% off  \n",
       "..      ...  \n",
       "95  74% off  \n",
       "96  86% off  \n",
       "97  73% off  \n",
       "98  89% off  \n",
       "99  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_reviews(url):\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver_1 = webdriver.Chrome(options=chrome_options)\n",
    "    driver_1.get(url)\n",
    "    \n",
    "    # Opening full reviews\n",
    "    full=driver_1.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\")\n",
    "    driver=webdriver.Chrome(options=chrome_options)\n",
    "    url=full.get_attribute('href')\n",
    "    driver.get(url)\n",
    "    driver_1.close()\n",
    "       \n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    def extract(driver):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "        for i in a:\n",
    "            rating.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "        for i in a:\n",
    "            review_summary.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\")\n",
    "        for i in a:\n",
    "            full_review.append(i.text)\n",
    "    \n",
    "    while(len(full_review)<10):\n",
    "        extract(driver)\n",
    "        \n",
    "    while(len(full_review)<100):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver.get(url)\n",
    "        extract(driver)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['rating']=rating\n",
    "    jobs['review_summary']=review_summary\n",
    "    jobs['full_review']=full_review\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>The built quality is not very premium.\\nThe ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>First thanks to Flipkart for this amazing deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I just directly switch from iphone 6s to iphon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         review_summary  \\\n",
       "0       5       Perfect product!   \n",
       "1       5          Great product   \n",
       "2       5     Highly recommended   \n",
       "3       5       Perfect product!   \n",
       "4       5       Perfect product!   \n",
       "..    ...                    ...   \n",
       "95      5     Highly recommended   \n",
       "96      5      Terrific purchase   \n",
       "97      5  Mind-blowing purchase   \n",
       "98      5         Simply awesome   \n",
       "99      5              Wonderful   \n",
       "\n",
       "                                          full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95  It's my first time to use iOS phone and I am l...  \n",
       "96  The built quality is not very premium.\\nThe ba...  \n",
       "97  First thanks to Flipkart for this amazing deal...  \n",
       "98  Excellent camera, good performance, no lag. Th...  \n",
       "99  I just directly switch from iphone 6s to iphon...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_reviews('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_100_sneakers(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Closing Pop-up\n",
    "    close_button=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    close_button.click()    \n",
    "    \n",
    "    \n",
    "    # searching required fields\n",
    "    search=driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    search.send_keys('sneakers')\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    discount=[]\n",
    "    \n",
    "    def extract(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div/div[3]\")[:number]\n",
    "        for i in a:\n",
    "            discount.append(i.text)\n",
    "    \n",
    "    while(len(discount)<40):\n",
    "        extract(driver,40)\n",
    "        \n",
    "    while(len(discount)<80):\n",
    "        next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract(driver_2,40)\n",
    "    \n",
    "    while(len(discount)<100):\n",
    "        next=driver_2.find_element_by_xpath(\"//a[@class='_1LKTO3'][2]\")\n",
    "        driver_3=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_3.get(url)\n",
    "        extract(driver_3,20)  \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand[:100]\n",
    "    jobs['des']=des[:100]\n",
    "    jobs['price']=price[:100]\n",
    "    jobs['discount']=discount[:100]\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,258</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Men Casual Sneakers For Men</td>\n",
       "      <td>₹1,048</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹378</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Swiggy</td>\n",
       "      <td>Casual Loafers, Sneakers Shoes for Men Pack of...</td>\n",
       "      <td>₹759</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BUCIK</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fila</td>\n",
       "      <td>JESS Sneakers For Men</td>\n",
       "      <td>₹1,359</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lotto</td>\n",
       "      <td>ATLANTA NEO Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      brand  \\\n",
       "0                  Red Tape   \n",
       "1   Bond Street By Red Tape   \n",
       "2                    Chevit   \n",
       "3       World Wear Footwear   \n",
       "4              Robbie jones   \n",
       "..                      ...   \n",
       "95                   Swiggy   \n",
       "96                    BUCIK   \n",
       "97                 Red Rose   \n",
       "98                     Fila   \n",
       "99                    Lotto   \n",
       "\n",
       "                                                  des   price discount  \n",
       "0                                    Sneakers For Men  ₹1,258  70% off  \n",
       "1                         Men Casual Sneakers For Men  ₹1,048  70% off  \n",
       "2   Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹499  75% off  \n",
       "3   Combo Pack of 4 Latest Collection Stylish Casu...    ₹499  75% off  \n",
       "4      Casual Sneakers Shoes For Men Sneakers For Men    ₹378  62% off  \n",
       "..                                                ...     ...      ...  \n",
       "95  Casual Loafers, Sneakers Shoes for Men Pack of...    ₹759  28% off  \n",
       "96                                   Sneakers For Men    ₹449  58% off  \n",
       "97                                   Sneakers For Men    ₹359  70% off  \n",
       "98                              JESS Sneakers For Men  ₹1,359  59% off  \n",
       "99                       ATLANTA NEO Sneakers For Men    ₹599  75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=flipkart_100_sneakers('https://www.flipkart.com/')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def myntra(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    price=driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "    price.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    color=driver.find_element_by_xpath(\"//li[@class='colour-listItem']/label/div\")\n",
    "    color.click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    brand=[]\n",
    "    des=[]\n",
    "    price=[]\n",
    "    \n",
    "    def extract_2(driver,number):\n",
    "                \n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")[:number]\n",
    "        for i in a:\n",
    "            brand.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4[1]\")[:number]\n",
    "        for i in a:\n",
    "            des.append(i.text)\n",
    "\n",
    "        a=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/div/span[1]\")[:number]\n",
    "        for i in a:\n",
    "            price.append(i.text)\n",
    "\n",
    "    \n",
    "    while(len(price)<50):\n",
    "        extract_2(driver,50)\n",
    "        \n",
    "    while(len(price)<100):\n",
    "        next=driver.find_element_by_xpath(\"//li[@class='pagination-next']/a\")\n",
    "        driver_2=webdriver.Chrome(options=chrome_options)\n",
    "        url=next.get_attribute('href')\n",
    "        driver_2.get(url)\n",
    "        extract_2(driver_2,50) \n",
    "    \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['brand']=brand\n",
    "    jobs['des']=des\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    driver_2.close()\n",
    "    \n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>des</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM Basketball Shoes</td>\n",
       "      <td>Rs. 8199Rs. 10295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men LEGEND REACT 3 Shoes</td>\n",
       "      <td>Rs. 6199Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Loafers</td>\n",
       "      <td>Rs. 6499Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Running Shoes</td>\n",
       "      <td>Rs. 6399Rs. 7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM FLY 3 Running Shoes</td>\n",
       "      <td>Rs. 11199Rs. 13995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 5839Rs. 7299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>Rs. 11249Rs. 14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Formal Oxfords</td>\n",
       "      <td>Rs. 7143Rs. 10990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Printed Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Bandit 5 Running</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                             des               price\n",
       "0                   Nike       Men ZOOM Basketball Shoes   Rs. 8199Rs. 10295\n",
       "1                   Nike        Men LEGEND REACT 3 Shoes    Rs. 6199Rs. 8295\n",
       "2              Cole Haan           Women Leather Loafers   Rs. 6499Rs. 12999\n",
       "3                   Nike          Men Zoom Running Shoes    Rs. 6399Rs. 7995\n",
       "4                   Nike    Men ZOOM FLY 3 Running Shoes  Rs. 11199Rs. 13995\n",
       "..                   ...                             ...                 ...\n",
       "95                  Xtep               Men Running Shoes    Rs. 5839Rs. 7299\n",
       "96             Cole Haan     Women Woven Design Sneakers  Rs. 11249Rs. 14999\n",
       "97  Heel & Buckle London      Men Leather Formal Oxfords   Rs. 7143Rs. 10990\n",
       "98                  FILA          Women Printed Sneakers            Rs. 7999\n",
       "99          UNDER ARMOUR  Women Charged Bandit 5 Running            Rs. 7999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=myntra('https://www.myntra.com/shoes')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "WEB SCRAPING ASSIGNMENT-2\n",
    ".\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon(url):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_box.send_keys('laptop')\n",
    "\n",
    "    button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "    button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    cpu_1=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i7']/span/a/div\")\n",
    "    cpu_1.click()\n",
    "\n",
    "    from selenium.common.exceptions import StaleElementReferenceException        # Importing Exception\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    try:\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    except StaleElementReferenceException as e:\n",
    "        driver.get('https://www.amazon.in/')\n",
    "        search_box=driver.find_element_by_id('twotabsearchtextbox')\n",
    "        search_box.send_keys('laptop')\n",
    "        button=driver.find_element_by_xpath(\"//div[@class='nav-right']\")\n",
    "        button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'filters')))\n",
    "        cpu_2=driver.find_element_by_xpath(\"//div[@id='filters']/ul/li[@aria-label='Intel Core i9']/span/a/div\")\n",
    "        cpu_2.click()\n",
    "    \n",
    "    title=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")[:10]\n",
    "    for i in a:\n",
    "        title.append(i.text)\n",
    "\n",
    "    rating=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//div[@class='a-row a-size-small']/span/span/a/i/span\")[:10]\n",
    "    for i in a:\n",
    "        rating.append(i.text)\n",
    "\n",
    "    price=[]\n",
    "\n",
    "    a=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")[:10]\n",
    "    for i in a:\n",
    "        price.append(i.text)\n",
    "        \n",
    "    jobs=pd.DataFrame({})\n",
    "    jobs['title']=title\n",
    "    jobs['rating']=rating\n",
    "    jobs['price']=price\n",
    "    \n",
    "    driver.close()\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td></td>\n",
       "      <td>57,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>97,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) MSI Prestige PE62 Core i7 7th Gen 15...</td>\n",
       "      <td></td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...</td>\n",
       "      <td></td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) ASUS ROG Strix G G531GT-AL018T 15.6\"...</td>\n",
       "      <td></td>\n",
       "      <td>69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td></td>\n",
       "      <td>51,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...</td>\n",
       "      <td></td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Nitro 5 Intel Core i7 10750H 15.6\" FHD IP...</td>\n",
       "      <td></td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title rating   price\n",
       "0  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...         82,490\n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...         57,999\n",
       "2  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...         97,700\n",
       "3  (Renewed) MSI Prestige PE62 Core i7 7th Gen 15...         57,990\n",
       "4  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...         74,990\n",
       "5  (Renewed) ASUS ROG Strix G G531GT-AL018T 15.6\"...         69,990\n",
       "6  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...         77,990\n",
       "7  Mi Notebook Horizon Edition 14 Intel Core i5-1...         51,999\n",
       "8  ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...         80,990\n",
       "9  Acer Nitro 5 Intel Core i7 10750H 15.6\" FHD IP...         78,990"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=amazon('https://www.amazon.in/')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
